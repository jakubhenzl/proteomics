---
title: "Bi1121: Proteomics (exercise)"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
---

# Introduction
We will be analyzing a data, which are label-free, bottom-up and generated by data-dependent acquisition. Raw spectra were searched using MaxQuant software, and we will start with the resulting **proteinGroups.txt** file, containing information about proteins identified and their quantification.

It is an interactomics study of **ubiquitin interactors**, based on articles of [Zhang, et al. 2017](https://www.cell.com/molecular-cell/fulltext/S1097-2765(17)30004-7) and [Zhang et al., 2018](https://www.nature.com/articles/nprot.2017.147).

For the analysis, we will be using [DEP package](https://www.bioconductor.org/packages/release/bioc/html/DEP.html) (Differential Enrichment analysis of Proteomics data).


# Libraries required

We will be using several libraries:

- here (path definitions)
- DEP (proteomics workflow)
- dplyr (basic data operations)
- SummarizedExperiment (normalization purposes)
- DT (output table generation)

Install the required packages using install.packages() or BiocManager, don't forget to comment the installation commands afterwards.

```{r libraries, message=FALSE, warning=FALSE}
# install.packages("package") 
# OR
# library("BiocManager")
# BiocManager::install("package")

library(here)
library(DEP)
library(dplyr)
library(DT)
library(SummarizedExperiment)
```

# Data input
On input, there is usually **proteinGroups.txt** file, generated by MaxQuant software. Read it into R using read.delim() or read.delim2() function.

```{r data-input, message=FALSE, warning=FALSE}
data <- read.delim(here('data', 'proteinGroups.txt'))
#data <- UbiLength # alternatively, use this command to get the data
nrow(data)
```

# Data preparation
## Contaminants filtering
We will filter out the most common contaminants:

* Reverse sequences
* Only identified by site proteins
* cRAP protein sequences (e.g common laboratory proteins, proteins added accidentally by dust/physical contact, etc.)
* keratins

By change of nrow() you can see how many proteins were filtered out 

```{r contaminants-filtering, message=FALSE, warning=FALSE}
data <- data %>%
  filter(Reverse != "+") %>%
  filter(!grepl("cRAP", Majority.protein.IDs)) %>%
  filter(Only.identified.by.site != "+") %>%
  filter(!grepl("keratin", Fasta.headers)) %>%
  filter(!grepl("Keratin", Fasta.headers)) %>%
  filter(!grepl("PE=5", Fasta.headers))

nrow(data)
```
## Unique identifiers 
Dataset has unique Uniprot identifiers, however those are not immediately informative. 
The associated gene names are informative, however these are not always unique. For further analysis these proteins must get unique names. Additionally, some proteins do not have an annotated gene name and for those we will use the Uniprot ID.

```{r unique-identifiers-a, message=FALSE, warning=FALSE}
# Are there any duplicated gene names?
data$Gene.names %>% duplicated() %>% any()

# Make a table of duplicated gene names
data %>% group_by(Gene.names) %>% summarize(frequency = n()) %>% 
  arrange(desc(frequency)) %>% filter(frequency > 1)
```

```{r unique-identifiers-b, message=FALSE, warning=FALSE}
# Make unique names using the annotation in the "Gene.names" column as primary names and the annotation in "Protein.IDs" as name for those that do not have an gene name.
data_unique <- make_unique(data, "Gene.names", "Protein.IDs", delim = ";")
```

## SummarizedExperiment

We will now create a SummarizedExperiment object and further work with it instead of classical dataframe.

For that, we need the columns containing intensities, and experimental design.

**Important**: by creating SummarizedExperiment, the protein intensities get **log2 transformed**! No need for a separate log2 transformation.

```{r summarized-experiment-CK1a-1-excluded, message=FALSE, warning=FALSE}
# grep the intensity columns
intensity_columns <- grep("LFQ.", colnames(data_unique)) 
# more often you will be using Intensity instead of LFQ intensity, so grep("Intensity.", colnames(data_unique))

# create experimental design
exp_design <- data.frame(
  label = c("Ubi4_1", "Ubi4_2", "Ubi4_3", 
            "Ubi6_1", "Ubi6_2", "Ubi6_3", 
            "Ctrl_1", "Ctrl_2", "Ctrl_3", 
            "Ubi1_1", "Ubi1_2", "Ubi1_3"),
  condition = c("Ubi4", "Ubi4", "Ubi4", 
                "Ubi6", "Ubi6", "Ubi6", 
                "Ctrl", "Ctrl", "Ctrl", 
                "Ubi1", "Ubi1", "Ubi1"),
  replicate = c(rep(1:3, times = 4))
)

# define the variable types
exp_design$label <- as.character(exp_design$label)
exp_design$condition <- as.character(exp_design$condition)
exp_design$replicate <- as.numeric(exp_design$replicate)

data_se <- make_se(data_unique, intensity_columns, exp_design)
```

# SummarizedExperiment intermezzo
```{r SE-intermezzo, message=FALSE, warning=FALSE}
# plot identifications per each condition
data_se
dim(data_se)
#dimnames(data_se)
#colData(data_se)
#assay(data_se)
head(assay(data_se))

#data_se$condition
#data_se@assays@data@listData
```

## Number of proteins
```{r plot-numbers, message=FALSE, warning=FALSE}
# plot identifications per each condition
plot_numbers(data_se)
```

## Data filtering

Proteomics data contain many missing values, therefore we pre-filter the dataset to get rid of the most unreliable identifications.

Firstly, we plot a barplot of the protein identification overlap between samples:
```{r filter-data-a, message=FALSE, warning=FALSE}
plot_frequency(data_se)
```

Based on that we can choose the filtering threshold using either of two functions:

- filter_missval(se, thr = 0)
- filter_proteins(se, type = c("complete", "condition", "fraction"), thr = NULL, min = NULL)

Thr means a threshold of allowed missing values in at least one condition. So, thr=1 means one missing value is allowed in at least one condition (2/3 replicates of >=1 condition)  

```{r filter-data-b, message=FALSE, warning=FALSE}
data_filt <- filter_missval(data_se, thr = 1)
plot_numbers(data_filt)
plot_frequency(data_filt)
```

# Normalization

We need to remove the technical variability using one of normalization approaches. DEP by default uses variance stabilizing normalization (**vsn**). We will try several more from the limma package:

**Vsn normalization**
```{r normalization-vsn, message=FALSE, warning=FALSE}
data_norm_vsn <- normalize_vsn(data_filt)
meanSdPlot(data_norm_vsn)
plot_normalization(data_filt, data_norm_vsn)
```

**Quantile normalization**
```{r normalization-quantile, message=FALSE, warning=FALSE}
data_norm_quant <- data_filt
assay(data_norm_quant)<-limma::normalizeQuantiles(assay(data_norm_quant))
meanSdPlot(data_norm_quant)
plot_normalization(data_filt, data_norm_quant)
```

**LoessF normalization**
```{r normalization-loessF, message=FALSE, warning=FALSE}
data_norm_loess <- data_filt
assay(data_norm_loess)<-limma::normalizeCyclicLoess(assay(data_norm_loess))
meanSdPlot(data_norm_loess)
plot_normalization(data_filt, data_norm_loess)
```

**Median normalization**
```{r normalization-median, message=FALSE, warning=FALSE}
data_norm_med <- data_filt
assay(data_norm_med)<-limma::normalizeMedianValues(assay(data_norm_med))
meanSdPlot(data_norm_med)
plot_normalization(data_filt, data_norm_med)
```

We will continue for now with the default, vsn normalization.

## Imputation of NAs

Proteomic data contain high number of missing values. There are three different **types of missing values**:

- **MCAR + MAR**: uniform occurence across data
- **MNAR**: proteins below detection limit, low abundance proteins

Based on the type of missingness, we choose appropriate **imputation algorithm**:

For MNAR:

- global minimum: imputes data by smallest non-missing value in the dataset
- QRILC: imputation using quantile regression-based left-censored function
- MinDet: imputation using minimal value, but sample-wise
- MinProb: imputation by random draws from a Gaussian distribution centered to a minimal value (q-th quantile)
- man: imputation by random draws from a manually defined left-shifted Gaussian distribution

For MCAR: 

- kNN: imputation by k-Nearest Neighbors averaging
- MLE: Maximum likelihood-based imputation method

For both, MNAR+MCAR:
- mixed imputation or use different package, e.g. imp4p

Plot heatmap of missing proteins in at least 1 condition (white = NA; black = present)
```{r imputation-heatmap, message=FALSE, warning=FALSE}
plot_missval(data_filt)
```

Plot intensity distributions and cumulative fraction of proteins with and without missing values
```{r imputation-distribution, message=FALSE, warning=FALSE}
plot_detect(data_filt)
```

Impute the missing values
```{r imputation, message=FALSE, warning=FALSE}
data_imp <- impute(data_norm_vsn, fun = "man", shift = 1.8, scale = 0.3)
plot_imputation(data_norm_vsn, data_imp)
```

Plot PCA for 500 most variable proteins
```{r imputation-pca, message=FALSE, warning=FALSE}
plot_pca(data_imp, x = 1, y = 2, n = 500, point_size = 4)
```


# Differential expression

We want to get differentially expressed proteins now, between the bait and control. For that, we will be using **limma** test.

```{r limma, message=FALSE, warning=FALSE}
# Test every sample versus control
data_diff <- test_diff(data_imp, type = "control", control = "Ctrl")

# Or we can manually define contrasts as well:
# Test manually defined comparisons
#data_diff_manual <- test_diff(data_imp, type = "manual", 
#                              test = c("Ubi4_vs_Ctrl", "Ubi6_vs_Ctrl"))
```


Now, we need to **set cutoffs** for calling a protein differentially expressed:
- logFC -> 1
- adjusted p-value -> 0.05

So, proteins with (logFC > 1 & adj.pvalue < 0.05) will be upregulated, and proteins with  (logFC < -1 & adj.pvalue < 0.05) will be downregulated.

We also need to correct for multiple testing, which in DEP is done by **fdrtools**.

```{r limma-cutoff, message=FALSE, warning=FALSE}
# Denote significant proteins based on user defined cutoffs
dep <- add_rejections(data_diff, alpha = 0.05, lfc = log2(1))
```

# Data visualization

Now let's see how our differentially expressed proteins look like:

## Correlation matrix
```{r correlation-matrix, message=FALSE, warning=FALSE}
# Plot the Pearson correlation matrix
plot_cor(dep, significant = TRUE, lower = 0, upper = 1, pal = "Reds")
```

## Heatmap of significant proteins
```{r heatmap-proteins, message=FALSE, warning=FALSE}
# Plot a heatmap of all significant proteins with the data centered per protein
plot_heatmap(dep, type = "centered", kmeans = TRUE, 
             k = 6, col_limit = 4, show_row_names = FALSE,
             indicate = c("condition", "replicate"))
```

## Heatmap of contrasts
```{r heatmap-contrasts, message=FALSE, warning=FALSE}
# Plot a heatmap of all significant proteins (rows) and the tested contrasts (columns)
plot_heatmap(dep, type = "contrast", kmeans = TRUE, 
             k = 6, col_limit = 10, show_row_names = FALSE)
```

## Volcano plots

Ubi1 vs Ctrl
```{r volcano-ubi1, message=FALSE, warning=FALSE}
plot_volcano(dep, contrast = "Ubi1_vs_Ctrl", label_size = 2, add_names = TRUE, adjusted = TRUE)
```

Ubi4 vs Ctrl
```{r volcano-ubi4, message=FALSE, warning=FALSE}
plot_volcano(dep, contrast = "Ubi4_vs_Ctrl", label_size = 2, add_names = TRUE, adjusted = TRUE)
```

Ubi6 vs Ctrl
```{r volcano-ubi6, message=FALSE, warning=FALSE}
plot_volcano(dep, contrast = "Ubi6_vs_Ctrl", label_size = 2, add_names = TRUE, adjusted = TRUE)
```

## Barplots of single proteins

We can also plot how proteins of our interest behave across conditions:
```{r barplots-single, message=FALSE, warning=FALSE}
plot_single(dep, proteins = "USP15")
plot_single(dep, proteins = "USP15", type = "centered")
```

## Plot_all()

Several types of plots can be also generated at once, using the plot_all command:
```{r plot-all, message=FALSE, warning=FALSE}
#plot_all(dep, plots = c("volcano", "heatmap", "single", "freq", "comparison"))
```

# Results table

Now, we will generate table with the results of differential expression:

```{r data-results, message=FALSE, warning=FALSE}
data_results <- get_results(dep)

# We can also get data in wide or long format:
# df_wide <- get_df_wide(dep)
# df_long <- get_df_long(dep)
```

For better work, we can also generate interactive table:
```{r data-results-interactive, message=FALSE, warning=FALSE}
data_results %>%
  select(ID, name, ends_with(c('_p.val', '_p.adj', '_ratio'))) %>%
    datatable(extensions = 'Buttons',
            options = list(dom = 'Blfrtip',
                           buttons = c('copy', 'csv', 'excel', 'pdf', 'print'),
                           lengthMenu = list(c(10,25,50,-1),
                                             c(10,25,50,"All"))))
```

We can also save the workspace for further use:
```{r data-save, message=FALSE, warning=FALSE}
save(data_se, data_norm_vsn, data_imp, data_diff, dep, file = here('outputs', "data.RData"))
# These data can be loaded in future R sessions using this command
# load("data.RData")
```

# SessionInfo()
Last, for the reproducibility, we should also save information about which packages we used using the SessionInfo() command:

```{r session-info, message=FALSE, warning=FALSE}
sessionInfo()
```

